**Classical Asumption Test**

**1. Multicollinearity test:** is used to determine existence of high
correlation between variables in a multiple regression model. If there
is a high correlation between the independent variables, then relation
between them of the dependent variable will be disrupted.

Hypothesis :

H0 : There is no multicolinearity

H1 : There is multicolinearity

Acceptance Criteria :

if VIF &lt;10, then not multicollinearity. Conversely, if the value of
VIF&gt; 10 there is multicollinearity

**2. Autocorrelation test**: is used to see that there is a linear
relation between the errors on a series of observations, sorted by time
(time series).

Hypothesis :

H0 : There is no autocorellation

H1 : There is autocorellation

Acceptance Criteria :

if the DWâ€™s value of calculated is outside the lower limit (dL) and the
upper limit (dV), then the model is not autocorrelation

**3. Heteroscedasticity test**: is used to test there is a regression
model residual variance inequality from one observation to another
observation.

Hypothesis :

H0 : There is no heteroscedasticity

H1 : There is heteroscedasticity

Acceptance Criteria :

The result value of test can be seen from value of significant. If the
significance value &gt; 0.05, then there is no heteroscedasticity.
Conversely, if the significance value &lt; 0.05 , then occurs
heteroscedaticity (Hill , Griffiths and Lim, 2011).

4\. **Normality test:** is used to determine whether or not the normal
distribution of data (Santoso, 2010)

Hypothesis :

H0 : The data comes from population that are normally distributed

H1 : The data comes from population that are not normally distributed

Acceptance Criteria :

Significance test of the value of T3 with Shapiro Wilk table can be seen
in the probability value (p). If the value of p&gt; 5%, then the data
are normally distributed. Conversely, when the value of p &lt; 5% , then
the data were not normally distributed
